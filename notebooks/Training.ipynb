{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from deeplearning_image_classification import data_loading\n",
    "\n",
    "from sklearn import model_selection, metrics\n",
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "from tensorflow.keras import applications\n",
    "#export\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "DATA_DIR = data_loading.DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/deeplearning_image_classification\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try removing this line on your PC, maybe you will not encounter [this issue](https://github.com/tensorflow/tensorflow/issues/24496)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "#policy = mixed_precision.Policy('mixed_float16')\n",
    "#mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "train_csv_path = os.path.join(DATA_DIR, 'train_metadata.csv')\n",
    "test_csv_path = os.path.join(DATA_DIR, 'test_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_metadata(train_metadata_path=train_csv_path, test_metadata_path=test_csv_path):\n",
    "    train_metadata_df = pd.read_csv(train_csv_path)\n",
    "    test_metadata_df = pd.read_csv(test_csv_path)\n",
    "    return train_metadata_df, test_metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/train_metadata.csv'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata_df, test_metadata_df = get_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 11000\n",
    "sample_val_size = 1000\n",
    "__, sample_train_val_metadata_df = model_selection.train_test_split(train_metadata_df, test_size=sample_size, random_state=2, stratify=train_metadata_df['class'])\n",
    "sample_train_metadata_df, sample_val_metadata_df = model_selection.train_test_split(sample_train_val_metadata_df, test_size=sample_val_size, random_state=2, stratify=sample_train_val_metadata_df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "image_size = (224, 224)\n",
    "train_batch_size = 32\n",
    "val_batch_size = 32\n",
    "test_batch_size = 64\n",
    "\n",
    "\n",
    "def get_train_val_test_iterators(train_metadata_df, val_metadata_df, test_metadata_df, image_size, train_batch_size, val_batch_size, test_batch_size):\n",
    "    image_gen = keras.preprocessing.image.ImageDataGenerator(\n",
    "        preprocessing_function=keras.applications.mobilenet_v2.preprocess_input,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "\n",
    "    train_image_iterator = image_gen.flow_from_dataframe(train_metadata_df, batch_size=train_batch_size, target_size=image_size,\n",
    "        shuffle=False)\n",
    "    val_image_iterator = image_gen.flow_from_dataframe(val_metadata_df, batch_size=val_batch_size, target_size=image_size, shuffle=False)\n",
    "    test_image_iterator = image_gen.flow_from_dataframe(test_metadata_df, batch_size=test_batch_size, target_size=image_size, shuffle=False)\n",
    "    return train_image_iterator, val_image_iterator, test_image_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 validated image filenames belonging to 82 classes.\n",
      "Found 1000 validated image filenames belonging to 82 classes.\n",
      "Found 10000 validated image filenames belonging to 82 classes.\n"
     ]
    }
   ],
   "source": [
    "train_image_iterator, val_image_iterator, test_image_iterator = get_train_val_test_iterators(sample_train_metadata_df, sample_val_metadata_df, test_metadata_df, image_size=image_size, train_batch_size=train_batch_size, test_batch_size=test_batch_size, val_batch_size=val_batch_size) \n",
    "n_classes = len(train_image_iterator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up model\n",
    "\n",
    "We use pretrained MobileNet model for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "learning_rate = 0.001\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.999\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=beta_1, beta_2=beta_2)\n",
    "default_metrics = ['acc', keras.metrics.Precision(), keras.metrics.Recall()]\n",
    "\n",
    "\n",
    "def setup_model(n_classes, optimizer, metrics):\n",
    "    base_model = keras.applications.MobileNet(include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            base_model,\n",
    "            keras.layers.AveragePooling2D((2, 2)),\n",
    "            keras.layers.Convolution2D(64, (2, 2)),\n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dense(n_classes),\n",
    "            keras.layers.Softmax()\n",
    "        ])\n",
    "    model.compile(\n",
    "        loss=keras.losses.CategoricalCrossentropy(),\n",
    "        optimizer=optimizer,\n",
    "        metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = setup_model(n_classes, optimizer, default_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenet_1.00_224 (Model)   (None, 7, 7, 1024)        3228864   \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 3, 3, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 2, 2, 64)          262208    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 82)                21074     \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 82)                0         \n",
      "=================================================================\n",
      "Total params: 3,512,146\n",
      "Trainable params: 283,282\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 313 steps, validate for 32 steps\n",
      "Epoch 1/10\n",
      " 94/313 [========>.....................] - ETA: 46s - loss: 6.3973 - acc: 0.1016 - precision: 0.1499 - recall: 0.0638"
     ]
    }
   ],
   "source": [
    "model.fit(train_image_iterator, validation_data=val_image_iterator, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(test_image_iterator).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array([test_image_iterator.class_indices[c] for c in test_metadata_df['class']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "sample_size = 11000\n",
    "sample_val_size = 1000\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(DATA_DIR)\n",
    "    train_metadata_df, test_metadata_df = get_metadata()\n",
    "    __, sample_train_val_metadata_df = model_selection.train_test_split(train_metadata_df, test_size=sample_size, random_state=2, stratify=train_metadata_df['class'])\n",
    "    sample_train_metadata_df, sample_val_metadata_df = model_selection.train_test_split(sample_train_val_metadata_df, test_size=sample_val_size, random_state=2, stratify=sample_train_val_metadata_df['class'])\n",
    "\n",
    "    train_image_iterator, val_image_iterator, test_image_iterator = get_train_val_test_iterators(\n",
    "        sample_train_metadata_df, sample_val_metadata_df, test_metadata_df,\n",
    "        image_size=image_size, train_batch_size=train_batch_size, test_batch_size=test_batch_size, val_batch_size=val_batch_size) \n",
    "    n_classes = len(train_image_iterator.class_indices)\n",
    "    model = setup_model(n_classes, optimizer, default_metrics)\n",
    "    model.fit(train_image_iterator, validation_data=val_image_iterator, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

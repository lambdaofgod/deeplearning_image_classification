{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from deeplearning_image_classification import data_loading\n",
    "\n",
    "from sklearn import model_selection, metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "import keras.applications\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "    \n",
    "#policy = mixed_precision.Policy('mixed_float16')\n",
    "#mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_path = os.path.join(data_loading.DATA_DIR, 'train_metadata.csv')\n",
    "test_csv_path = os.path.join(data_loading.DATA_DIR, 'test_metadata.csv')\n",
    "\n",
    "train_metadata_df = pd.read_csv(train_csv_path)\n",
    "test_metadata_df = pd.read_csv(test_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 11000\n",
    "sample_val_size = 1000\n",
    "__, sample_train_val_metadata_df = model_selection.train_test_split(train_metadata_df, test_size=sample_size, random_state=2, stratify=train_metadata_df['class'])\n",
    "sample_train_metadata_df, sample_val_metadata_df = model_selection.train_test_split(sample_train_val_metadata_df, test_size=sample_val_size, random_state=2, stratify=sample_train_val_metadata_df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15008</th>\n",
       "      <td>139046</td>\n",
       "      <td>Verbenaceae</td>\n",
       "      <td>293f237272df889747b628ad5ab4d766c474955b</td>\n",
       "      <td>../data/images_train/data/324932/293f237272df889747b628ad5ab4d766c474955b.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119283</th>\n",
       "      <td>197578</td>\n",
       "      <td>Lauraceae</td>\n",
       "      <td>c221d86a85270537a7b1bcfe0729157e1e697ad6</td>\n",
       "      <td>../data/images_train/data/158370/c221d86a85270537a7b1bcfe0729157e1e697ad6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133029</th>\n",
       "      <td>13881</td>\n",
       "      <td>Poaceae</td>\n",
       "      <td>a3e74644ac6d90799bf8cd1ae7b4b13da8ec69ae</td>\n",
       "      <td>../data/images_train/data/265835/a3e74644ac6d90799bf8cd1ae7b4b13da8ec69ae.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152296</th>\n",
       "      <td>173446</td>\n",
       "      <td>Rubiaceae</td>\n",
       "      <td>77d096981f4a90ed8d31926dcdf985a24eaa10e8</td>\n",
       "      <td>../data/images_train/data/293108/77d096981f4a90ed8d31926dcdf985a24eaa10e8.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91208</th>\n",
       "      <td>262151</td>\n",
       "      <td>Piperaceae</td>\n",
       "      <td>c23a20c276c9d50e461f5d5eaf60838b0d728df1</td>\n",
       "      <td>../data/images_train/data/253046/c23a20c276c9d50e461f5d5eaf60838b0d728df1.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0        class                                      name  \\\n",
       "15008       139046  Verbenaceae  293f237272df889747b628ad5ab4d766c474955b   \n",
       "119283      197578    Lauraceae  c221d86a85270537a7b1bcfe0729157e1e697ad6   \n",
       "133029       13881      Poaceae  a3e74644ac6d90799bf8cd1ae7b4b13da8ec69ae   \n",
       "152296      173446    Rubiaceae  77d096981f4a90ed8d31926dcdf985a24eaa10e8   \n",
       "91208       262151   Piperaceae  c23a20c276c9d50e461f5d5eaf60838b0d728df1   \n",
       "\n",
       "                                                                             filename  \n",
       "15008   ../data/images_train/data/324932/293f237272df889747b628ad5ab4d766c474955b.jpg  \n",
       "119283  ../data/images_train/data/158370/c221d86a85270537a7b1bcfe0729157e1e697ad6.jpg  \n",
       "133029  ../data/images_train/data/265835/a3e74644ac6d90799bf8cd1ae7b4b13da8ec69ae.jpg  \n",
       "152296  ../data/images_train/data/293108/77d096981f4a90ed8d31926dcdf985a24eaa10e8.jpg  \n",
       "91208   ../data/images_train/data/253046/c23a20c276c9d50e461f5d5eaf60838b0d728df1.jpg  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_train_metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 validated image filenames belonging to 82 classes.\n",
      "Found 1000 validated image filenames belonging to 82 classes.\n",
      "Found 10000 validated image filenames belonging to 82 classes.\n"
     ]
    }
   ],
   "source": [
    "image_gen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=keras.applications.mobilenet_v2.preprocess_input,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "image_size = (224, 224)\n",
    "\n",
    "\n",
    "sample_train_image_iterator = image_gen.flow_from_dataframe(sample_train_metadata_df, batch_size=32, target_size=image_size,\n",
    "    shuffle=False)\n",
    "sample_val_image_iterator = image_gen.flow_from_dataframe(sample_val_metadata_df, batch_size=32, target_size=image_size, shuffle=False)\n",
    "test_image_iterator = image_gen.flow_from_dataframe(test_metadata_df, batch_size=64, target_size=image_size, shuffle=False)\n",
    "\n",
    "n_classes = len(sample_train_image_iterator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up model\n",
    "\n",
    "We use pretrained MobileNet model for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.MobileNet(include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        base_model,\n",
    "        keras.layers.AveragePooling2D((4, 4)),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(n_classes),\n",
    "        keras.layers.Softmax()\n",
    "    ])\n",
    "model.compile(\n",
    "    loss=keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=['acc', keras.metrics.Precision(), keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenet_1.00_224 (Model)   (None, 7, 7, 1024)        3228864   \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 82)                84050     \n",
      "_________________________________________________________________\n",
      "softmax_1 (Softmax)          (None, 82)                0         \n",
      "=================================================================\n",
      "Total params: 3,312,914\n",
      "Trainable params: 84,050\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 4.1882 - acc: 0.1422 - precision_1: 0.3715 - recall_1: 0.0406 - val_loss: 4.3075 - val_acc: 0.1820 - val_precision_1: 0.5060 - val_recall_1: 0.0420\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 3.2319 - acc: 0.2361 - precision_1: 0.5470 - recall_1: 0.0826 - val_loss: 4.4887 - val_acc: 0.1980 - val_precision_1: 0.5385 - val_recall_1: 0.0630\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 36s 117ms/step - loss: 2.7835 - acc: 0.3053 - precision_1: 0.6451 - recall_1: 0.1238 - val_loss: 3.9418 - val_acc: 0.1890 - val_precision_1: 0.5038 - val_recall_1: 0.0660\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 37s 120ms/step - loss: 2.5215 - acc: 0.3492 - precision_1: 0.7091 - recall_1: 0.1582 - val_loss: 4.2375 - val_acc: 0.1920 - val_precision_1: 0.5000 - val_recall_1: 0.0660\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 38s 121ms/step - loss: 2.3083 - acc: 0.3971 - precision_1: 0.7240 - recall_1: 0.1807 - val_loss: 4.9744 - val_acc: 0.2070 - val_precision_1: 0.4767 - val_recall_1: 0.0820\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 52s 166ms/step - loss: 2.1348 - acc: 0.4351 - precision_1: 0.7575 - recall_1: 0.2177 - val_loss: 5.2471 - val_acc: 0.1880 - val_precision_1: 0.3583 - val_recall_1: 0.0670\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 56s 178ms/step - loss: 2.0203 - acc: 0.4614 - precision_1: 0.7710 - recall_1: 0.2387 - val_loss: 4.3997 - val_acc: 0.1910 - val_precision_1: 0.3846 - val_recall_1: 0.0850\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 54s 174ms/step - loss: 1.9092 - acc: 0.4861 - precision_1: 0.7805 - recall_1: 0.2642 - val_loss: 5.1866 - val_acc: 0.2020 - val_precision_1: 0.4244 - val_recall_1: 0.0870\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 58s 185ms/step - loss: 1.8100 - acc: 0.5086 - precision_1: 0.7997 - recall_1: 0.2911 - val_loss: 4.1980 - val_acc: 0.1970 - val_precision_1: 0.3790 - val_recall_1: 0.0830\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 54s 172ms/step - loss: 1.7232 - acc: 0.5317 - precision_1: 0.8084 - recall_1: 0.3148 - val_loss: 5.1609 - val_acc: 0.1820 - val_precision_1: 0.3629 - val_recall_1: 0.0940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f55ed0b49d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sample_train_image_iterator, validation_data=sample_val_image_iterator, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(test_image_iterator).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array([test_image_iterator.class_indices[c] for c in test_metadata_df['class']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1983"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

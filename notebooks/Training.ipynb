{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import os\n",
    "from deeplearning_image_classification import data_loading\n",
    "\n",
    "from sklearn import model_selection, metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "    \n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_path = os.path.join(data_loading.DATA_DIR, 'train_metadata.csv')\n",
    "test_csv_path = os.path.join(data_loading.DATA_DIR, 'test_metadata.csv')\n",
    "\n",
    "train_metadata_df = pd.read_csv(train_csv_path)\n",
    "test_metadata_df = pd.read_csv(test_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "__, sample_metadata_df = model_selection.train_test_split(train_metadata_df, test_size=1000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 validated image filenames belonging to 82 classes.\n",
      "Found 10000 validated image filenames belonging to 82 classes.\n"
     ]
    }
   ],
   "source": [
    "image_gen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
    "image_size = (224, 224)\n",
    "\n",
    "\n",
    "sample_image_iterator = image_gen.flow_from_dataframe(sample_metadata_df, batch_size=48, target_size=image_size)\n",
    "test_image_iterator = image_gen.flow_from_dataframe(test_metadata_df, batch_size=64, target_size=image_size, shuffle=False)\n",
    "\n",
    "\n",
    "n_classes = len(sample_image_iterator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up model\n",
    "\n",
    "We use pretrained MobileNet model for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.applications\n",
    "\n",
    "\n",
    "base_model = keras.applications.MobileNet(include_top=False, input_shape=(224, 224, 3))\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        base_model,\n",
    "        keras.layers.AveragePooling2D((4, 4)),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(n_classes),\n",
    "        keras.layers.Softmax()\n",
    "    ])\n",
    "model.compile(loss=keras.losses.CategoricalCrossentropy(), optimizer=keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenet_1.00_224 (Model)   (None, 7, 7, 1024)        3228864   \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 82)                84050     \n",
      "_________________________________________________________________\n",
      "softmax_1 (Softmax)          (None, 82)                0         \n",
      "=================================================================\n",
      "Total params: 3,312,914\n",
      "Trainable params: 3,291,026\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "21/21 [==============================] - 22s 1s/step - loss: 4.1816\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 10s 458ms/step - loss: 2.4778\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 10s 459ms/step - loss: 1.3892\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 10s 459ms/step - loss: 0.6487\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 10s 458ms/step - loss: 0.3235\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 10s 454ms/step - loss: 0.2225\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 10s 455ms/step - loss: 0.1627\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 10s 458ms/step - loss: 0.1167\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 10s 466ms/step - loss: 0.0916\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 10s 466ms/step - loss: 0.0531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7faa99ca7a10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sample_image_iterator, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(test_image_iterator).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array([test_image_iterator.class_indices[c] for c in test_metadata_df['class']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1566"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
